{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5c2659-f399-4fb6-9b9d-1f4a37dc0028",
   "metadata": {},
   "source": [
    "### Import libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844204bf-dc34-4bc4-9604-8ce7d2fc98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functionalities\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# datetime manipulation\n",
    "import datetime as dt\n",
    "import time\n",
    "from time import sleep\n",
    "from datetime import timedelta\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Deep learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Deep learning model persistence\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Graphing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e2bcf-9cc0-401d-8be5-286df75a8734",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Mcahine Learning - LSTM Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a6b88-7ccc-4ce3-84ba-d6179886531a",
   "metadata": {},
   "source": [
    "### Preprocessing for LSTM\n",
    "\n",
    "Dataframe (stock_df) specified below needs to be close prices with all indicators (fundamental + technical) to be passed as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3554b2-cb43-40df-a3ed-43ef0cb712f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create signal dataframe as a copy\n",
    "signal = stock_df.copy()\n",
    "\n",
    "# Remove all NaN  resulting from unavailable indicator signals\n",
    "signal = signal.dropna()\n",
    "\n",
    "# Create blank row for current trading day and append to end of dataframe\n",
    "signal = signal.append(pd.Series(name = signal.index.max() + timedelta(days = 1)))\n",
    "\n",
    "# # Create target\n",
    "signal['target'] = signal['close'] \n",
    "\n",
    "# Shift indicators to predict current trading day close\n",
    "signal.iloc[:, :-1]  = signal.iloc[:, :-1].shift()\n",
    "\n",
    "# Drop first row with NaNs resulting from data shift\n",
    "signal = signal.iloc[1:, :]\n",
    "\n",
    "# Ensure all data is ('float64')\n",
    "signal = signal.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06f41a-af3f-4350-a9ee-b34856265739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and target\n",
    "\n",
    "X = signal.iloc[:, :-1]\n",
    "y = signal['target']\n",
    "# Write function to first convert X and y into arrays, train-test split according to train_proportion, and scale for LSTM processing\n",
    "\n",
    "\n",
    "def scale_array(features, target, train_proportion:float = 0.8, scaler: bool = True):\n",
    "    \n",
    "    '''\n",
    "    Prepares four arrays for training within an LSTM neural network. \n",
    "    Returns the following objects\n",
    "    X_train: training set for features\n",
    "    X_test: testing set for features\n",
    "    y_train: training set for target(s)\n",
    "    y_test: testing set for target(s)\n",
    "    scaler: sklearn MinMaxScaler with fit memory required for inverse transformation of model predictions\n",
    "    \n",
    "    Parameters:    \n",
    "    :features: Pandas dataframe or Series object containing model features\n",
    "    :target: Pandas dataframe or Series object containing moel target(s)\n",
    "    :train: Proportion of data to be assigned to train set. The rest will be assigned to test set.\n",
    "    :scaler: Boolean. Default = True.If False, data will not be scaled.\n",
    "    '''\n",
    "    # Convert features and target to arrays\n",
    "    X = np.array(features)\n",
    "    y = np.array(target).reshape(-1,1)\n",
    "    \n",
    "    # Manually splitting the data\n",
    "    split = int(0.8 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    if scaler:\n",
    "        # Create a MinMaxScaler object\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        # Fit the MinMaxScaler object with the features data X\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        # Scale the features training and testing sets\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Fit the MinMaxScaler object with the target data Y\n",
    "        scaler.fit(y_train)\n",
    "\n",
    "        # Scale the target training and testing sets\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_test = scaler.transform(y_test)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Reshape the features data to pass into LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2b622-f09e-422b-bfb0-5c09b019024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call scale_array on X and y to preprocess data for LSTM.\n",
    "\n",
    "X_train, X_test, y_train, y_test, scaler = scale_array(X, y, train_proportion = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b03c4-28e9-4114-b5eb-b9291ef88760",
   "metadata": {},
   "source": [
    "### Build and Train the LSTM Neural Network\n",
    "\n",
    "Below are a couple of helper functions to streamline the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d554f-cdef-41f4-85b1-1855bd1e48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(\n",
    "    train_set: np.ndarray,\n",
    "    dropout: float = 0.2,\n",
    "    layer_one_dropout: float = 0.6,\n",
    "    number_layers: int = 4,\n",
    "    optimizer: str = 'adam',\n",
    "    loss: str = 'mean_squared_error'):\n",
    "    \n",
    "    '''\n",
    "    Initialises a multilayer LSTM neural network, with number of units in the first layer being equal to the number of features. Number of layers is default 4, but can be specified by user.\n",
    "    Each layer is accompanied by a Dropout with a rate of 0.6 for the first layer and a default of 0.2 for subsequent layers.\n",
    "    After the first layer, number of units in each LSTM are reduced to 2/3 the initial size.\n",
    "    '''\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Initial model setup\n",
    "    number_units = X_train.shape[1]\n",
    "    number_hidden_nodes = number_units/3*2\n",
    "    dropout_fraction = 0.4\n",
    "\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(LSTM(\n",
    "        units=number_units,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], 1))\n",
    "        )\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    number_units = int(number_units/3*2)\n",
    "\n",
    "    # Intiialize layer counter\n",
    "    layer_counter = 1\n",
    "    \n",
    "    # 'While' loop to keep adding layers until number of layers meet user specifications. Condition is \"< - 1\" because of need for penultimate layer not to have \"return_sequences = True\".\n",
    "    while layer_counter < (number_layers - 1):\n",
    "        # Layer 2 to n\n",
    "        model.add(LSTM(units=number_units, return_sequences = True))\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        layer_counter+=1\n",
    "\n",
    "    # Penultimate layer\n",
    "    model.add(LSTM(units=number_units))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892262c-ab81-4cbf-8553-dccfc1a42b49",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "\n",
    "- The while loop below will repeatedly run the LSTM learning process given the parameters below. \n",
    "- Essentially, the cumulative returns produced by the strategy on the test data set has to meet the target cumulative returns (user-specified). Otherwise, it will run a new iteration.\n",
    "- `max_iter` sets the maximum no. of iterations to run before the loop gives up, and that should hint to the user that a better model/feature input might be needed.\n",
    "- `trading_threshold` sets the target returns within the specified timeframe that will trigger a trading signal from the strategy. E.g. if your trading threshold is 0.10, the strategy will only fire a trading signal if it predicts your returns will be more than 10%. \n",
    "\n",
    "\n",
    "#### Performance metrics:\n",
    "\n",
    "- -**Loss on testing data set**\n",
    "    - The loss metric on X_test, y_test\n",
    "- **RMSE**\n",
    "    - Root mean square error between predicted prices and actual prices\n",
    "- **Cumulative returns**\n",
    "    - Probably more important, given we want a trading algo to generate high returns. I've included the min/max so you can get an idea of how this changes across the testing period. If an algo produces high returns but performs really poorly at its `min`, that might indicate a risky trading strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e1e8f-3b2b-4496-b51b-9a0eb1bb7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set strategy cumulative return\n",
    "strategy_cumulative_return = 0\n",
    "\n",
    "# Set target cumulative returns as a threshold for model to achieve.\n",
    "target_cumulative_return = 1.2\n",
    "\n",
    "# Initialise model iteration counter\n",
    "iter_counter = 0\n",
    "\n",
    "# Set returns threshold for strategy to fire trading signal\n",
    "trading_threshold = 0.15\n",
    "\n",
    "# Set maximum numberof iterations to run\n",
    "max_iter = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2dc651-db42-403b-bfc5-e13263c360c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set strategy cumulative return\n",
    "strategy_cumulative_return = 0\n",
    "\n",
    "# Set target cumulative returns as a threshold for model to achieve.\n",
    "target_cumulative_return = 1.4\n",
    "    \n",
    "# Initialise model iteration counter\n",
    "iter_counter = 0\n",
    "\n",
    "# Set threshold for strategy to initiate a trade\n",
    "trading_threshold = 0.15\n",
    "\n",
    "# Set maximum numberof iterations to run\n",
    "max_iter = 10\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "while strategy_cumulative_return < target_cumulative_return:\n",
    "    \n",
    "    # Start iteration counter\n",
    "    iter_counter+=1\n",
    "    \n",
    "    # Create model if first iteration. Reset model if subsequent iterations\n",
    "    model = create_LSTM_model(X_train,\n",
    "                              dropout=0.4,\n",
    "                              layer_one_dropout=0.6,\n",
    "                              number_layers=4\n",
    "                             )\n",
    "\n",
    "    # Set early stopping such that each iteration stops running epochs if validation loss is not improving (i.e. minimising further)\n",
    "    callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=40, mode='auto',\n",
    "        restore_best_weights=False\n",
    "    )\n",
    "    \n",
    "    # Print message to allow visual confirmation of iteration training is currently at.\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Training model iteration {iter_counter}...please wait.\\n\")\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=1000, batch_size=64,\n",
    "        shuffle=False,\n",
    "        validation_split = 0.1,  \n",
    "        verbose = 0,\n",
    "        callbacks = callback\n",
    "    )\n",
    "    \n",
    "    # Print confirmation that current iteration has ended.\n",
    "    print(f\"Iteration {iter_counter} ended.\")\n",
    "   \n",
    "    # Evaluate loss when predicting test data\n",
    "    model_loss = model.evaluate(X_test[:-1], y_test[:-1], verbose=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(predicted)\n",
    "    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    # Create a DataFrame of Real and Predicted values\n",
    "    prices = pd.DataFrame({\n",
    "        \"Actual\": real_prices.ravel(),\n",
    "        \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = signal.index[-len(real_prices): ]) \n",
    "    \n",
    "    # Calculate actual daily returns\n",
    "    prices['actual_returns'] = prices['Actual'].pct_change()\n",
    "    # Create a 'last close' column\n",
    "    prices['last_close'] = prices['Actual'].shift()\n",
    "    # Calculate the predicted daily returns, by taking the predicted price as a proportion of the last close\n",
    "    prices['predicted_returns'] = (prices['Predicted'] - prices['last_close'])/prices['last_close']\n",
    "\n",
    "    # Actual signal = 1 if actual returns more than threshold,  -1 if less than threshold\n",
    "    prices['actual_signal'] = 0\n",
    "    prices.loc[prices['actual_returns'] > trading_threshold , 'actual_signal'] = 1\n",
    "    prices.loc[prices['actual_returns'] < -trading_threshold , 'actual_signal'] = -1\n",
    "    prices['actual_signal'].value_counts()\n",
    "    \n",
    "    # Strategy signal = 1 if predicted returns > threshold, -1 if less than threshold\n",
    "    prices['strategy_signal'] = 0\n",
    "    prices.loc[prices['predicted_returns'] > trading_threshold , 'strategy_signal'] = 1\n",
    "    prices.loc[prices['predicted_returns'] < -trading_threshold , 'strategy_signal'] = -1\n",
    "    prices['strategy_signal'].value_counts()\n",
    "    \n",
    "    # Compute strategy returns\n",
    "    prices['strategy_returns'] = prices['actual_returns'] * prices['strategy_signal']\n",
    "    \n",
    "    # Compute strategy cumulative returns\n",
    "    strategy_cumulative_return = (1+prices['strategy_returns']).cumprod()[-1]\n",
    "    \n",
    "    # Print performance metrics of the model given the feature weights produced by current iteration\n",
    "    print(f\"LSTM Method iteration {iter_counter} - performance\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Model loss on testing dataset: \\n{model_loss:.4f}\")\n",
    "    print(f\"Cumulative return on testing dataset: \\n{strategy_cumulative_return}\")\n",
    "    \n",
    "    if strategy_cumulative_return < target_cumulative_return:\n",
    "        print(f\"Target cumulative returns not met.\\n\")\n",
    "        if iter_counter == max_iter:\n",
    "            print(f\"The LSTM model was not able to achieve the target cumulative returns on the testing dataset within {max_iter} iterations.\\n\")\n",
    "            break\n",
    "    elif strategy_cumulative_return >= target_cumulative_return:\n",
    "        print(f\"Target cumulative returns achieved\\n\")        \n",
    "        \n",
    "\n",
    "# Record time it took for the current iteration, and calculate average time per iteration\n",
    "total_time_elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))\n",
    "average_time_per_iteration = time.strftime(\"%H:%M:%S\", time.gmtime((time.time() - start_time)/iter_counter))\n",
    "\n",
    "print(f\"Total time elapsed: {total_time_elapsed}\")\n",
    "print(f\"Average time taken to train {iter_counter} model(s): {average_time_per_iteration}\")\n",
    "\n",
    "# Calculate cumulative returns at their best and worst time points over time.\n",
    "min_return = (1+prices['strategy_returns']).cumprod().min()\n",
    "max_return = (1+prices['strategy_returns']).cumprod().max()\n",
    "\n",
    "# Print cumulative return performance\n",
    "print(f\"From {prices.index.min()} to {prices.index.max()}, the cumulative return of the current model is {strategy_cumulative_return:.2f}.\")\n",
    "print(f\"At its lowest, the model recorded a cumulative return of {min_return:.2f}.\")\n",
    "print(f\"At its highest, the model recorded a cumulative return of {max_return:.2f}.\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1ab13-faa8-4cd2-bd9d-0042c9822cbf",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "Once we have a model that generates the desired cumulative returns, we can print the graph for further visual confirmation that this is a suitable algo. \n",
    "\n",
    "Three graphs here \n",
    "- The loss metric from the training history of the eligible model\n",
    "- Predicted prices vs Actual prices\n",
    "- Strategy cumprod vs Actual cumprod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dae687-af7d-4530-b344-eb5b3f4b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation loss versus training loss\n",
    "\n",
    "plt.plot(history.history['loss'], 'r', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'g', label='Validation loss')\n",
    "plt.title('Training VS Validation loss')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf8bdb-af5e-412a-b957-6fc4eb7b1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the real vs predicted prices as a line chart\n",
    "price_fig = px.line(prices, y = ['Actual', 'Predicted'],  title = \"Actual vs Predicted\", width= 1500, height = 600)\n",
    "price_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3bd99-0b48-4e2e-a7e8-35d911a135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot strategy cumulative returns\n",
    "strategy_cumulative_returns = (1+prices['strategy_returns']).cumprod()\n",
    "actual_cumulative_returns = (1+prices['actual_returns']).cumprod()\n",
    "cumulative_returns_df = pd.concat([strategy_cumulative_returns, actual_cumulative_returns], join = \"inner\", axis = \"columns\")\n",
    "\n",
    "cumulative_returns_fig = px.line(\n",
    "    cumulative_returns_df,\n",
    "    y = ['strategy_returns', 'actual_returns'],\n",
    "    x = cumulative_returns_df.index.values,\n",
    "    title = f'Strategy  vs Actual Returns',\n",
    "    width = 1500, height = 600\n",
    ")\n",
    "\n",
    "cumulative_returns_fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb94edd-4c47-4500-bd05-a43a7ae8f09d",
   "metadata": {},
   "source": [
    "#### Note\n",
    "Note that if we're using a threshold for buy/sell, the classification report is not very helpful. This is because e.g. if the model predicts returns more than the threshold for the current window, but returns turn out to be positive *but* less than the threshold, you'd still make $$$, but your strategy signal will be = 1 and the actual signal will be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1a300-9fa3-4970-9d26-3cb599c81260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(prices['actual_signal'], prices['strategy_signal'], zero_division =1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94bf16-9d86-4074-9564-1ed37a9bcf0f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model Persistence (Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2aefe-7be1-4782-aab6-41adf9594374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to json\n",
    "model_json = model.to_json()\n",
    "\n",
    "# Save model layout as json\n",
    "file_path = Path(f\"../LSTM_model_weights/{ticker}.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save weights\n",
    "file_path = f\"../LSTM_model_weights/{ticker}.h5\"\n",
    "model.save_weights(f\"saved_models/{ticker}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13984a32-b537-407b-b599-85b421de95f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Forward Prediction and Trading Signals given saved model weights\n",
    "\n",
    "### Model Persistence (Load)\n",
    "\n",
    "Note that I've set up the file name here to save as (ticker_name).json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971345d9-eb3f-4d8c-80a1-4b4e7d0f101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json and create mdoel\n",
    "file_path = Path(f\"./saved_models/{ticker}.json\")\n",
    "with open (file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "file_path = f\"./saved_models/{ticker}.h5\"\n",
    "loaded_model.load_weights(file_path)\n",
    "\n",
    "# Visual confirmation of model setup\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b5c2d-e550-4ba9-953d-b197f60e4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "predicted = loaded_model.predict(X_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
